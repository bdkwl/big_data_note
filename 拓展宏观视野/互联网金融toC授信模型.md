## 背景介绍

### 互联网金融行业数据分析师角色
互联网金融的本质是风控, 数据分析师在这行业基本上有两种角色：
1. 风控分析师：除了一定的模型理解能力, 还需要大量的行业和法律法规经验
2. 数据建模师：要求对算法的理解较深, 相对来说对行业经验要求不是很高

在产品对象上分为toB和toC：
- toB：定量打分卡+定性行业经验
- toC：个人信用分

无论是toB和toC, 在决策上当前最依赖的都是央行征信报告

### 数据建模师工作内容
关键词：
- 数据源：准确理解产品数据源系统数据表结构
- 开发信用评分卡模型：开发贷前、贷中、贷后相关模式（如贷前预判断模型、拒件信用评分卡、催收评分卡等等）
- 模型上线监控维护
- 数据挖掘：分析产品的数据信息, 预估、识别及衡量信贷风险

## 授信模型 —— “芝麻信用”

### 芝麻信用分结构
身份：稳定性。根据学历以及职业经历信息, 以及实名消费行为
履约能力：兜底性。综合考虑用户各方面资产信息来判断履约能力
信用历史：历史性。信用卡有无逾期等等守约行为
人脉关系：稳定性验证+弱价值性。
行为偏好：真正价值。根据用户购物、缴费、转账等行为体现的行为特点

### 数据变量

数据变量分为原始变量和衍生变量。
- 原始变量：直接存储的数据库里的最基础变量。如用户的每天交易额
- 衍生变量：因为金融的本质是风险, 所以都要对原始变量进行加工转化。一般有以下三种：
    1. 时间维度衍生：最近1个月的交易额、最近3个月的交易额
    2. 函数衍生：最大交易额、最小交易额、交易额方差
    3. 比率衍生：最近1个月交易额/最近3个月交易额

在选择变量时, 基于RFM原则（即最近、频次、钱）, 所有跟这三个属性相关的变量都要优先保留

### 数据处理
所有数据处理、数据建模都是为业务服务。实际工作中数据处理和数据建模都是慢慢迭代优化的。常见的前期数据处理工作有以下三种：
1. 数值型和字符串型字段缺失性和合理性检验, 剔除无效字段
2. 数值型字段的相关性验证：过滤相关性非常强的字段变量
3. 字符串型字段的离散化处理

### 数据标准化
所有变量都已经数值化后, 但在量级和量刚上相差很大(如交易额和交易次数, 这是没有可比性), 需要对所有字段进行标准化。选择合适的标准化方法即可。

### 数据建模前思考
**在建模前, 理清楚业务目标, 从而确定使用什么模型**

> 以芝麻信用分为例

背景：身份、履约能力、信用历史、人脉关系、行为偏好5大模块在不同时期的权重不一样, 所以每个模块都要单独建模

目的：希望根据用户在这5大模块的综合芝麻分给用户一些其他额外服务。如花呗借呗免押金, 同时保证用户不违约

逻辑：根据用户的数据算出用户违约的概率, 这个概率也可以转化为用户的分数。所有逻辑回归模型自然就用上了

### 具体方案反推
> 综合芝麻分--> 综合概率 --> 5个模块各自的概率加权 --> 每个模块的逻辑回归模型 --> 每个模块的训练集和测试集

以历史信用为例：
假设该模块包含的字段有：
- 最近一个月主动查询金融机构信用次数 x1
- 最近一个月需还贷总额 x2
- 最近一个月逾期总额 x3
- 拟合系数 a, b, c

计算用户违约概率 P

```math
P = 1 / (1 + e^-(ax1+bx2+cx3) )
```

### 模型离线效果指标

离线模型主要参考两个参数：
- 混淆矩阵：查准率和查全率
- ROC曲线：根据混淆矩阵得出, 区分模型是否能较好的把好坏样本分开的图形。一般取ROC下面的面积AUC来衡量模型效果, 越大越好, 一般至少0.6以上



## 模型落地

### 落地前
> 设计好数据模型后, 找落地场景。芝麻信用围绕吃喝玩乐进行各种产品服务

举例：
根据芝麻信用分申请招联金融信用额度。

涉及到两个公司的产品合作

- 合作前工作：
1. 招联金融提供一批样本用户数据给芝麻, 芝麻的数据建模师根据模型计算出这批用户的违约概率
2. 招联金融根据芝麻给出的用户违约概率, 计算模型的准确度(招联金额有自己一套计算模型规则)。
3. 比较模型准确度, 觉得在合理范围, 双方才会正式合作

### 落地中
> 正式落地时, 招联对每个用户评估信用时, 芝麻信用分只是一个参考维度

1. 机器调用该用户的央行征信报告评估X
2. 接口调用用户的芝麻信用分Y
3. 该用户在招联的信用评估情况Z

基于X,Y,Z, 招联内部再根据专家规则出一套授信方案。

### 落地后
> 前期招联金融和芝麻对坏账。调整模型参数降低坏账情况, 这个时候模型的参数调整才是最有意义的

调参方法：
1. 找出是子模型引起还是所有模型引起
2. 如果是子模型引起, 直接调整该模型参数
3. 如果是整体模型出现问题, 那就要重新进行数据处理(如WOE分组、更换衍生变量、字符型字段重新打分等等)


