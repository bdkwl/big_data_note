## Hive系统架构
![Hive系统架构]()

用户接口（让外部应用程序进行访问）包括

- CLI（命令行工具）
- HWI（web接口，网页浏览器访问数据）
- JDBC、ODBC（编程语言访问数据的接口）
- Thrift Server（提供外部程序进行RPC调用）

驱动模块（Driver）包括编译器、优化器、执行器等。负责把HiveSQL语句转换成MapReduce作业

元数据存储模块（Metastore）是一个独立的关系型数据库（自带derby数据库，或MySQL数据库）

## Hive工作原理

### SQL语句转换成MapReduce作业的基本原理

1 join 实现原理

![join实现原理]()

表数据 -> Map处理成key-value键值对 -> Shuffle对键值对分区、排序，发送给不同的Reduce任务 -> Reduce输出连接数据结果 

2 group by 实现原理

分组（Group By）操作把表Score的不同片段按照rank和level的组合值进行合并，计算不同rank和level的组合值分别有几条记录：
select rank, level ,count(*) as value from score group by rank, level

![groupby实现原理]()

表数据 -> Map：key-value键值对，key是rank与level的组合、value是组合出现次数 -> Shuffle分区排序 -> Reduce：讲key（rank、level组合值）相同的数据进行合并，输出数据结果


### Hive中SQL查询转换成MapReduce作业的基本原理

当用户向Hive输入一段命令或查询时，Hive需要与Hadoop交互工作来完成该操作：

- 驱动模块接收该命令或查询编译器
- 对该命令或查询进行解析编译
- 由优化器对该命令或查询进行优化计算
- 该命令或查询通过执行器进行执行

作业过程：

![hive中sql查询]()

1. 由Hive驱动模块中的编译器对用户输入的SQL语言进行词法和语法解析，将SQL语句转化为抽象语法树的形式
2. 抽象语法树的结构仍很复杂，不方便直接翻译为MapReduce算法程序，因此，把抽象语法书转化为查询块
3. 把查询块转换成逻辑查询计划，里面包含了许多逻辑操作符
4. 重写逻辑查询计划，进行优化，合并多余操作，减少MapReduce任务数量
5. 将逻辑操作符转换成需要执行的具体MapReduce任务
6. 对生成的MapReduce任务进行优化，生成最终的MapReduce任务执行计划
7. 由Hive驱动模块中的执行器，对最终的MapReduce任务进行执行输出

- 当启动MapReduce程序时，Hive本身是不会生成MapReduce算法程序的
- 需要通过一个表示“Job执行计划”的XML文件驱动执行内置的、原生的Mapper和Reducer模块
- Hive通过和JobTracker通信来初始化MapReduce任务，不必直接部署在JobTracker所在的管理节点上执行
- 通常在大型集群上，会有专门的网关机来部署Hive工具。网关机的作用主要是远程操作和管理节点上的JobTracker通信来执行任务
- 数据文件通常存储在HDFS上，HDFS由名称节点管理

## Hive HA基本原理
Hive HA（High Availability）

问题：在实际应用中，Hive也暴露出不稳定的问题
- 由多个Hive实例进行管理的，这些Hive实例被纳入到一个资源池中，并由HAProxy提供一个统一的对外接口
- 对于程序开发人员来说，可以把它认为是一台超强“Hive"

