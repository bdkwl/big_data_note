##MapReduce工作流程

### 工作流程

![MapReduce工作流程]()

不同的Map任务之间不会进行通信

不同的Reduce任务之间也不会发生任何信息交换用户不能显式地从一台机器向另一台机器发送消息

所有的数据交换都是通过MapReduce框架自身去实现的

### MapReduce各个执行阶段
![MapReduce各个执行阶段]()

流程：

1.  从文件系统（HDFS）加载文件
2.  InputFormat（读取文件数据，格式验证，将输入文件数据集做分片给split
3. RR（RecordReader,将数据输出<key, value>，作为下一步Map的输入）
4. Map(编写的处理逻辑，完成对数据的相关处理。处理结束输出中间结果<key,value>) 
5. Shuffle（数据分区、排序、合并、归并，将键值对分发给相应的Reduce任务进行处理）
6. Reduce(编写的处理逻辑，完成对数据的分析，输出最终结果<key, value>) 
7. OutPutFormat（对输出数据进行格式检查，写入到分布式文件系统HDFS） 

split（分片）：HDFS 以固定大小的block 为基本单位存储数据，而对于MapReduce 而言，其处理单位是split。split 是一个逻辑概念，它只包含一些元数据信息，比如数据起始位置、数据长度、数据所在节点等。它的划分方法完全由用户自己决定

Map任务的数量：Hadoop为每个split创建一个Map任务，split 的多少决定了Map任务的数目。大多数情况下，理想的分片大小是一个HDFS块Reduce任务的数量：- 最优的Reduce任务个数取决于集群中可用的reduce任务槽(slot)的数目- 通常设置比reduce任务槽数目稍微小一些的Reduce任务个数（这样可以预留一些系统资源处理可能发生的错误）

### Shuffle过程

![Shuffle过程]()

Map端的Shuffle过程

![Map端Shuffle]()

- 每个Map任务分配一个缓存- MapReduce默认100MB缓存
- 设置溢写比例0.8- 分区默认采用哈希函数- 排序是默认的操作- 排序后可以合并（Combine）- 合并不能改变最终结果- 在Map任务全部结束之前进行归并- 归并得到一个大的文件，放在本地磁盘- 文件归并时，如果溢写文件数量大于预定值（默认是3）则可以再次启动Combiner，少于3不需要- JobTracker会一直监测Map任务的执行，并通知Reduce任务来领取数据合并（Combine）和归并（Merge）的区别：
两个键值对<“a”,1>和<“a”,1>，如果合并，会得到<“a”,2>，如果归并，会得到<“a”,<1,1>>

Reduce端的Shuffle过程

![Reduce端Shuffle]()

- Reduce任务通过RPC向JobTracker询问Map任务是否已经完成，若完成，则领取数据
- Reduce领取数据先放入缓存，来自不同Map机器，先归并，再合并，写入磁盘
- 多个溢写文件归并成一个或多个大文件，文件中的键值对是排序的
- 当数据很少时，不需要溢写到磁盘，直接在缓存中归并，然后输出给Reduce