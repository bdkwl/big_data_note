## AB测试介绍

> AB测试时为Web或App界面或者流程制作两个（A/B）或多个（A/B/n）版本，在同一时间维度，分别让组成成分相同（相似）的访客群组随机访问这些版本，收集各群组的用户体验数据和业务数据，最后分析评估出最好版本正式采用

关键词

- 组成成分相同的访客：用户群要一样
- 同一时间：一定要同一时间段对比，否则没有意义
- 用户体验数据和业务数据：AB测试指标体系

### AB测试流程
1. 根据数据分析得到某建议项
2. 根据建议项，产品经理得到某落地项
3. 根据某落地项，研发设计人员进行开发设计（先设计，再丢到AB测试平台里面去跑数据）
4. 研发人员数据采集：自动采集数据
5. 分析师跟进AB效果：显著性在95%以上并维持一段时间，实验可结束

### 常见的两种AB测试类型
- UI界面型

![UI界面型](https://raw.githubusercontent.com/bdkwl/big_data_note/master/%E4%B8%93%E9%A2%98%E5%88%86%E6%9E%90%E6%A0%87%E5%87%86%E5%8C%96%E6%B5%81%E7%A8%8B/AB%E6%B5%8B%E8%AF%95-UI%E7%95%8C%E9%9D%A2%E5%9E%8B.png)


以上图（墨迹天气）的小人：在产品设计之初，要不要增加一个小人只是一个想法，而这必须要经过AB测试才能说要不要实现。因此A版本没有小人，B版本有小人，结果是B版本的数据比A版本要好，所以最终有小人

所有设计师都要有AB测试的思想才能更棒，认为好看好用不一定靠谱

- 算法策略型

![算法策略型](https://raw.githubusercontent.com/bdkwl/big_data_note/master/%E4%B8%93%E9%A2%98%E5%88%86%E6%9E%90%E6%A0%87%E5%87%86%E5%8C%96%E6%B5%81%E7%A8%8B/AB%E6%B5%8B%E8%AF%95-%E7%AE%97%E6%B3%95%E7%AD%96%E7%95%A5%E5%9E%8B.png)

以上图（小红书）针对新用户的内容推荐：

- A策略：100%兴趣预选
- B策略：80%兴趣预选 + 20%随机内容

当前对于任何一款个性化内容APP，给用户的推荐都涉及到大量的算法策略型AB测试

一般而言，AB两个组样本都要在10万以上才可以初步看数据


## AB测试注意事项

- AB两组是否真的相同 —— 研发负责搭建，但分析师要知道大概原理
	
	要确保AB两组只有一个变量不同，通过最终数据来看这个变量是正向还是负向效应
	
- 策略是否生效 —— 研发说进行了AB测试，但分析师要去抽样看
- AB测试评估指标体系 —— 要在AB测试之前，与研发沟通好看哪些综合性指标。

	考虑好最终要用哪些指标来评估效果，最好是能设计出一套综合性的指标体系，后续做实验直接看报表数据即可，不用每次单独建表
	
- 多观察几天数据 —— 前3天都是在一个试验阶段，数据参考价值不大（不过能很好的看出试验是否有问题），4-10天数据相对比较稳定，可以当作测试结论
- AB测试的存档规划 —— 所有AB都要文档化，方便后续找增长点
	
	定期复盘做了哪些AB，预期效果与实际效果，这也是落地项的闭环。建议用4W2H方法来管理AB测试
	
AB测试项 |  具体内容 What | 为何测试 Why | 测试时间 When | 测试负责人 Who | 预期效果 How | 实际效果 How much 
--- | --- | --- | --- | --- | --- | --- 

文档是数据分析师日常非常重要工作之一，标准化、规范化



## AB测试的思考
对于设计师：设计思维 + AB测试，在效率上还是效果上，都有极大的提升

对于产品：AB测试的闭环能让我们更好的了解用户；同时通过AB测试去总结出我们的用户喜欢什么样的策略和界面，让AB测试本身自我迭代

对于分析师：对大多数改动都不会带来大幅效果提升，AB测试效果都是略好，所以要持续迭代。如果某个试验效果非常好，要注意是试验本身出现的问题还是什么因素

专题分析也是一个持续的过程，越来越深入，越来越了解用户和产品



